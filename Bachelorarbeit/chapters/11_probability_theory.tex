\chapter{Probability Theory Foundations}~\label{chap:foundations}

This part of the thesis mainly serves to introduce the necessary fundamentals to describe the later algorithms and to establish  consistent notation.
The results of \cref{sec:random_fields,sec:chaining} especially will become important in \cref{chap:bound}.
For a more in depth treatment of the subjects of this chapter, we refer the reader to literature such as~\cite{bremaud2020probability,bovier2022stochastic}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Basics %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Basic Probability}~\label{sec:basics}
% 
Probability theory often concerns itself with the probability of drawing from a certain subset instead of drawing one specific result.
Given the task of guessing a random number between 0 and 1, the probability of any single guess being correct is zero (without prior knowledge about how was randomly picked). 
But the probability of drawing from a certain subset of \( [0,1] \), for example \([0,0.3]\) has a non-zero probability. This gives rise to a more meaningful way to describe the random behavior.
For that reason, we will start this chapter not with probability theory, but with a treatment of measuring subsets. Specifically we start with measure theory.

As it turns out, finding a measure for all subsets of $\mathbb{R}$ that coincides with the measure induced by the Euclidean distance on all open intervals is not possible, assuming the axiom of choice, due to the Vitali set~\cite{vitali1905sul}. As a next best thing, we will not work with the set of all subsets, but with $\sigma$-algebras instead.


\begin{definition}[$\sigma$-Algebra]\index{$\sigma$-Algebra}
    Let $\Omega$ be a set. The collection \( \mathcal{A} \subseteq \mathcal{P} (\Omega) \) is called a \textit{$\sigma$-algebra} if
    \begin{enumerate}[(i)]
        \item $\Omega$ is in $\mathcal{A}$.
        \item $\mathcal{A}$ is closed under complementation, for \( A \in \mathcal{A} \) we have \( A^{C} \in \mathcal{A} \).
        \item $\mathcal{A}$ is closed under countable unions, for \( A_{1}, A_{2}, \dots \in \mathcal{A} \) we have \( \bigcup_{k \in \mathbb{N}} A_{k} \in \mathcal{A} \)
    \end{enumerate}
    We refer to the elements of the $\sigma$-algebra as events\index{random!event}. The tuple \( (\Omega,\mathcal{A})\) is called a \textit{measurable space}. 
\end{definition}

Some trivial examples of $\sigma$-algebras for any set $\Omega$ include the collection \( \{\emptyset, \Omega\} \) as well as the power set $\mathcal{P}(\Omega)$.
But the useful cases often live in between the two extremes. One commonly used construction is that of the smallest $\sigma$-algebra that contains a certain set of events $\mathcal{M}$. To obtain it we can take the intersection of all $\sigma$-algebras containing $X$ and are guaranteed a unique $\sigma$-algebra~\cite[p.52]{bremaud2020probability}. This $\sigma$-algebra is called the \textit{$\sigma$-algebra generated by $\mathcal{M}$}, we write \( \sigma(\mathcal{M}) \).
The $\sigma$-algebra generated by the open sets of the topology of a space has a special name, it is called the Borel $\sigma$-algebra $\mathcal{B}$. 
In \( \mathbb{R}^{n} \) the Borel $\sigma$-algebra $\mathcal{B}(\mathbb{R}^{n})$ is also generated by the set of open balls with radius \( \varepsilon > 0 \). 
% As a note for the topology inclined reader, this is in essence a consequence of the separability of $\mathbb{R}^{n}$. \textcolor{red}{Or is it? Cite?}

\begin{definition}[Measure]\index{measure}
    Let \( (\Omega,\mathcal{A}) \) be a measurable space. A function \( \mu \colon \mathcal{A} \to [0,\infty] \) is called a  \textit{measure} on \( (\Omega,\mathcal{A}) \) if \( \mu(\emptyset) = 0 \) and if for any sequence \( \{A_{n}\}_{n \geq 0} \) of pairwise disjoint sets in $\mathcal{A}$, the following property ($\sigma$-additivity) is satisfied
    \[
        \mu( \sum_{n=0}^{\infty} A_{n}) = \sum_{n=0}^{\infty} \mu(A_{n}).
    \]
\end{definition}
The triple \( (\Omega, \mathcal{A}, \mu) \) is called a \textit{measure space}\index{measure space}. If \( \mu(\Omega) = 1 \), we call it a \textit{probability measure}\index{probability measure} and \( (\Omega, \mathcal{A}, \mu) \) a \textit{probability space}\index{probability space}.
As an example of a measure let us look at the Lebesgue measure $\lambda^{n}$ on \( (\mathbb{R}^{n}, \mathcal{B}(\mathbb{R}^{n})) \). 
We will not explicitly define the measure for all sets.
Instead, we can define the measure on a generator of the Borel $\sigma$-algebra, and are guaranteed uniqueness~\cite[p.61]{bremaud2020probability} by an application of Carath√©odory's Theorem.
Thus we define
\[
    \lambda^{n} \left( \prod_{i=1}^{n} (a_{i},b_{i}] \right) \coloneqq \prod_{i=1}^{n} (b_{i}-a_{i})
\]
for all \( a_{i}, b_{i} \in \mathbb{R} \). Another canonical example is the \textit{Dirac measure}. For \( a \in \Omega \), it is defined as \( \delta_{a}(C) = 1_{C}(a) \).

% If not otherwise stated, we will work with the Lebesgue/Borel (???) $\sigma$-algebra and the Lebesgue measure $\lambda$.

% https://mathoverflow.net/questions/31603/why-do-probabilists-take-random-variables-to-be-borel-and-not-lebesgue-measura
% Answer to Borel Lebesgue question: We want the second sigma algebra to be as small as possible


Now that we have established the notions of $\sigma$-algebras, measurable spaces and measures, we can talk about measureable functions. 
We call a function \( f \colon \Omega \to E \) between two measurable spaces \( (\Omega,\mathcal{A}) \) and \( (E,\mathcal{E}) \) a \textit{measureable function}\index{measurable function} with respect to $\mathcal{A}$ and $\mathcal{E}$ if 
\[ f^{-1}(C) \in \mathcal{A}  \text{ for all } C \in \mathcal{E}. \] 
Note that the definition of measureability does not require a measure, but only a measurable space. 
A measurable function \( f \colon (\Omega,\mathcal{A}) \to (\mathbb{R}, \mathcal{B}(\mathbb{R})) \) satisfying
\[
    \int_{\Omega} \lvert f \rvert \dx[\mu] < \infty
\]
is called a \textit{$\mu$-integrable function}.





\begin{definition}[\( \mathcal{L}^{p} \) spaces, \( L^{p} \) spaces]\index{\( L^{p} \) space}
    Let \((\Omega, \mathcal{A}, \mu)\) be a measure space, $E$ a Banach space with norm \( \lVert \cdot \rVert \). For \( 1 \leq p \leq \infty \) we define
    the vector space
    \[
        \mathcal{L}^{p}(\Omega,\mathcal{A}, \mu; E) \coloneqq \left\{ f \colon \Omega \to E \,\mid\, \lVert f \rVert_{p} < \infty \right\}.
    \] 
    with the seminorm
    \[
        \lVert f \rVert_{p} \coloneqq \left( \int_{\Omega} \lVert f \rVert^{p} \dx[\mu] \right)^{1/p}
    \]
    for \( p < \infty \) and
    \[
        \lVert f \rVert_{\infty} = \inf \{ C \geq 0 : \lvert f(x) \rvert \leq C \text{ for almost every x} \}.
    \]
    Define the equivalence relation
    \[
        f \sim g \colon \iff \mu(\{f(x) \neq g(x)\}) = 0.
    \]
    Then factorizing by $\sim$, we arrive at the Banach space 
    \[
        L^{p} \coloneqq \mathcal{L}^{p} / \sim
    \]
    with norm
    \[
        \lVert [f] \rVert_{p} \coloneqq \lVert f \rVert_{p}.
    \]
\end{definition}
Whenever obvious from the context, we will not mention the underlying sets, instead writing \( L^{p} \). We will also write $f$ instead of \([f]\)  for an element \([f] \in L^{p} \).



% Probability theory



Now let us shift the notation from the analytic and measure theoretic view to the probabilistic view. Instead of dealing with functions $f$, we now have random variables $X$. Instead of integrating $f$, we take the expected value \( E[X] \).
\begin{definition}[Random variables]\index{random!variable}
    Let  \( (\Omega,\mathcal{A}, \Prob) \) be a probability space and let \( (E,\mathcal{E}) \) be a measurable space. A measurable function 
    \[
        X \colon (\Omega, \mathcal{A}) \to  (E, \mathcal{E})
    \]
    is called a \textit{random element} with values in $E$. If \( E = \mathbb{R} \) and \( \mathcal{A} = \mathcal{B}(\mathbb{R}) \), it is called a \textit{random variable}. If \( E = \mathbb{R}^{n} \) and \( \mathcal{A} = \mathcal{B}(\mathbb{R}^{n}) \) for some \( n \in \mathbb{N} \), it is called a \textit{random vector}\index{random!vector}.
\end{definition}

Dealing with the one dimensional case first, the expected value\index{expectation} of a random variable $X$ is defined as 
\[
    \E[X] \coloneqq \int_{\Omega} X \dx[\Prob]
\]
and its variance\index{variance} as
\[
    \Var[X] \coloneqq \E\left[(X-\E[X])^{2}\right].
\]
The covariance\index{covariance} between two random variables $X$ and $Y$ is given by
\[
    \Cov(X,Y) = \E[ (X-\E[X]) (Y-\E[Y])].
\]
For a random vector \( X = (X_{1}, \dots, X_{n})^{T} \), such that \( X_{1}, \dots X_{n} \) are square integrable random variables, we define the \textit{mean}
\[
    \mu_{X} \coloneqq \E[X] = (\E[X_{1}], \dots, \E[X_{n}])^{T}
\]
and the \textit{covariance matrix} of $X$
\[
\Sigma_{X} \coloneqq \E\left[(X-\E[X])(X-\E[X])^{T}\right]
= \{\sigma_{X_{i}, X_{j}} \}_{1 \leq i,j \leq n}.
\]
Take any $y \in \mathbb{R}^{n}$, The calculation
\begin{align*}
    y^{T} \Sigma_{X} y &= y^{T} \E\left[(X-\E[X])(X-\E[X])^{T}\right] y \\
    &= \E\left[y^{T} (X-\E[X])(X-\E[X])^{T}y\right]\\
    &=\E\left[\left\lVert (X-\E[X])^{T} y \right\rVert^2\right] \geq 0.
\end{align*}
shows that the covariance matrix is always positive semidefinite.
Now we have some tools to describe random variables globally. But we do not have the structure to describe them locally yet.
We say a random element $X$  with values in a measurable space \( (E, \mathcal{E}) \) has a \textit{distribution}\index{distribution} $\Prob_{X}$ on \( (E, \mathcal{E}) \), which is given by the image of the probability measure $\Prob$ mapping $X$ from \( (\Omega,\mathcal{A}) \) to \( (E, \mathcal{E}) \), that is, for all \( C \in \mathcal{E}\) we have 
\[
    \Prob_{X}(C) = \Prob(X \in C).
\]
Note that \( \Prob_{X} \) is a measure on \( (E, \mathcal{E}) \).
The \textit{cumulative distribution function} (\textsc{cdf}) \( F_{X} \) of a random variable is given by
\[
    F_{X}(x) = \Prob_{X}((-\infty,x]) = \Prob(X \leq x)
\]
for any $x$.
For two random variables $X$ and $Y$ we define the \textit{joint cumulative distribution function}
\[
    F_{X,Y}(x,y) = \Prob(X \leq x, Y \leq y).
\]
Two random variables $X$ and $Y$ are called \textit{independent}\index{independent random variables} of each other if the joint cumulative distribition function can be decomposed into
\[
    F_{X,Y}(x,y) = F_{X}(x) F_{Y}(y)
\]
for all \( x,y \).
If, for a random variable $X$, there exists a real valued function $f_{X}$, such that 
\[
    \Prob( X \in A) = \int_{A} f_{X} \dx[\Prob]
\]
for all \( A \in \mathcal{A} \), we say $f_{X}$ is the \textit{probability density function}\index{probability density function}(\textsc{pdf}) of $X$.
% \textcolor{red}{PDF of a random vector}
% Without going into further detail, this notion can be expanded to more measures than just distributions of random variables by defining in a wider context the Radon Nikodym derivative\index{Radon Nikodym derivative} \(\frac{ \dx[\Prob_{X}]}{\dx[\Prob]} \coloneqq f_{X}\)~\cite[p. 24]{bovier2022stochastic}.
% \textcolor{red}{leave radon nikodym derivative out?}
% \textcolor{red}{Say: can be expanded to densities of measures, not just measures coming from distributions of random variables}
If a random variable $X$ has a density $f_{X}$, then its expected value is also given by
\[
    \E[X] = \int_{-\infty}^{\infty} x f_{X}(x) \dx,
\]
the expected value of a random variable mapped by a function $g$ is given by
\[
    \E[g(X)] = \int_{-\infty}^{\infty} g(x) f_{X}(x) \dx.
\]
% \begin{figure}[t]
%     \centering
%     \input{figures/normal_distribution_plot.pgf}
%     \caption{Probability density functions of Gaussian random variables with different $\sigma$ and $\mu$.}
% \end{figure}


It is often useful to give an alternative characterization of a distribution. 
Two common approaches are the characteristic function and the moment generating function. Both give a unique and complete alternative characterization of a distribution.
The \textit{characteristic function}\index{characteristic function} $\varphi_{X}$ of a random variable $X$ is defined by the Fourier transformation
   \[
       \varphi_{X}(u) = \E\left[e^{i u X}\right].
   \]
Similarly, the characteristic function of a real random vector $X$ is defined by
   \[
       \varphi_{X}(u) = \E\left[e^{i u^{T} X}\right].
   \]
The \textit{moment generating function}\index{moment generating function} (\textsc{mgf}) of a random variable $X$ is
\[
    M_{X}(u) = \E\left[e^{u X}\right],
\]
provided that this expectation exists in a neighbourhood of \( u = 0 \).
Similarly we define
\[
    M_{X}(u) = \E\left[e^{u^{T} X}\right]    
\]
for a random vector $X$.
Characteristic functions have some useful properties. 
For independent variables $X$ and $Y$, the characteristic function of \( X+Y \) has the property
\[
    \varphi(X+Y) = \varphi(X) \varphi(Y).
\]



Later, when we take measurements of a stochastic process, the measurments will be incorporated into the model by conditioning the prior probability on the measurements.
Before we do that in the context of stochastic processes, let us look at how random variables can be conditioned.
Similar to the conditional probability \( \Prob(A \mid B) = \frac{\Prob( A \cap B)}{\Prob(B)} \) for events $A$ and $B$,
there also is a \textit{conditional probability distribution}\index{conditional!probability distribution}
\[
    f_{X \mid Y}(x,y) = \begin{cases} \frac{f_{X,Y}(x,y)}{f_{Y}(y)} \text{ if } f_{Y}(y) > 0\\ 
        0 \text{ otherwise}\end{cases} 
\]
for random variables \( X,Y \) with densities \( f_{X}, f_{Y} \).
If these are jointly distributed random variables, \( f_{Y} \) is often computed as a \textit{marginal density} \( f_{Y}(y)= \int f_{X,Y}(x,y) \dx \).
We further define the \textit{conditional (cumulative) distribution} of $X$ given $Y=y$ by
\[
    \Prob(X \leq x \mid Y = y) = \int_{-\infty}^{x} f_{X \mid Y}(\vartheta ,y) \dx[\vartheta],
\]
as well as the \textit{conditional expectation}\index{conditional!expectation}
\[
    \E[X \mid Y = y] = \int_{-\infty}^{\infty} x f_{X \mid Y}(x,y) \dx.
\]
More generally, consider a probability space \( (\Omega,\mathcal{A},\Prob) \) with a sub-algebra \( \mathcal{H} \subset \mathcal{A}  \) and a random variable $X$. A $\mathcal{H}$-measurable function \( \E[X \mid \mathcal{H}] \) satisfying
\[
    \int_{H} \E[X \mid \mathcal{H}] \dx[\Prob] = \int_{H} X \dx[\Prob]
\]
for all \( H \in \mathcal{H} \) is called the \textit{conditional expectation} of $X$ given $\mathcal{H}$.
The existence and uniqueness of this object is not trivial, we refer to \cite{bremaud2020probability} for a treatment of that matter.
One important example of a sub-algebra often used in this context, is that of a $\sigma$-algebra generated by a random element \( Y \colon (\Omega,\mathcal{A}) \to (E,\mathcal{E}),\) denoted by \(\sigma(Y)\). It is the smallest $\sigma$-algebra containing all the pre-images of open sets, so \( \sigma(Y) = \{ Y^{-1}(A) \mid A \in \mathcal{E} \} \). When working with random variables, one can pick any generating set of the Borel $\sigma$-algebra $\mathcal{B}$, like the right bounded intervals \(\{(-\infty,a]\mid a \in \mathbb{R} \}\) which yields \(  \sigma(Y)= \left\{ \{ Y \leq a\} \mid a \in \mathbb{R}\right\} \).
If we are conditioning with a $\sigma$-algebra generated by a random variable $Y$, we write
\[
    \E[X \mid Y] = \E[X \mid \sigma(Y)].
\]
The variance also lends itself to conditioning
\[
    \Var[ X \mid Y] = \E\left[   (X - \E[X \mid Y])^2 \mid Y\right].
\]
%
%
%
\begin{example}[Uniform distribution]\index{distribution!uniform}
    Let $a,b \in \mathbb{R}$. A real random variable $X$ with probability density function
\[
    f(x) = \frac{1}{b-a} 1_{[a,b]}
\]
is called a \textit{uniform} random variable on \( [a,b] \). This is denoted by \( X \sim \mathcal{U}([a,b]) \).
The \textsc{cdf} of $X$ is given by
\[
    F_{X}(x) = 
    \begin{cases} 
        0 \text{ for } x < a,\\
        \frac{x-a}{x-b} \text{ for } a \leq x \leq b, \\
        1 \text{ for } x > b.
    \end{cases}
\]
\end{example}
% 
\begin{figure}
    \centering
    \input{figures/normal_distribution_plot.pgf}
    \caption{Two normal distributions with different $\sigma$ and $\mu$.}
    \label{fig:normal_distribution_plot}
\end{figure}
% 
% 
\begin{example}[Normal distribution]\index{distribution!normal}
A random variable $X$ with \textsc{pdf}
\[
    f(x)=\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2} \frac{(x - \mu)^2}{\sigma^2}},
\]
where \( \mu \in \mathbb{R} \) and \( \sigma \in \mathbb{R}_{+} \), is called a \textit{Gaussian} random variable. We also say $X$ is normally distributed. This is denoted by \( X \sim \mathcal{N}(\mu, \sigma^2) \). Two examples of normal distributions are shown in \cref{fig:normal_distribution_plot}.
A random vector $X$ with \textsc{pdf}
\[
    f(x)=\frac{1}{\sqrt{(2 \pi)^{d} \det(\Sigma) }} \exp\left(  -\frac{1}{2} (x-\mu)^{T}\Sigma^{-1}(x-\mu)\right),
\]
where $x$ is a vector of input variables and $\Sigma$ is the covariance matrix,
is called a \textit{multivariate Gaussian} random vector.
In this case we also say that its components $x_{i}$ are jointly Gaussian.
\end{example}
Gaussian random variables have some properties, that make them easier to work with.
To mention one, uncorrelated Gaussian random variables are automatically independent~\cite[Thm. 3.2.7]{bremaud2020probability}. 
Now that we have seen two first examples of probability distributions, let us take a closer look at how to distributions.
Under some weak assumptions, the laws of large numbers assert that the sums of independent random variables are likely to be near their expected values. 
These sums serve as fundamental examples of random variables that are concentrated around their mean.
As we will see on a few examples, this behavior is common among many functions of independent random variables. 
\begin{figure}[t]
    \centering
    \input{figures/tail_distribution_kernels.pgf}
    \caption{Two distributions with different tail behaviors.}
    \label{fig:tail_distribution_kernels}
\end{figure}
This leads us to concentration\index{concentration} inequalities.
They usually take the form of bounds for the tails \(X - \mu\), such as
\[
    \Prob(\lvert X-\mu \rvert \geq x) \leq \text{something small.}
\]
We can see different tail behaviors of two distributions shown in \cref{fig:tail_distribution_kernels}.
A first example of a concentration inequality is \textit{Markov's inequality}\index{Markov's inequality}.
Note that for any nonnegative random variable $X$ and any \( t > 0 \), 
\[
    X \geq t \mathbf{1}_{\{X \geq t\}},
\]
where $\mathbf{1}_{\{X \geq t\}}$ is the indicator function of the event $\{X \geq t\}$.
Taking the expectation of both sides yields Markov's inequality
\[
    \E[X] \geq t \Prob(X \geq t).
\]
It follows from Markov's inequality that if \( \varphi \) is a strictly monotonically increasing nonnegative function, then for any random variable $X$ and any real number $t$
\[
    \Prob(X \geq t) = \Prob( \varphi(X) \geq \varphi(t)) \leq \frac{\E[\varphi(X)]}{\varphi(t)}.
\]
The application of \( \varphi(x) = x^2 \) leads to \textit{Chebyshev's inequality}\index{Chebyshev's inequality}. For an arbitrary random variable $X$ and $t>0$
\[
    \Prob(\lvert X - \E[X] \rvert \geq t) = \Prob( \lvert X - \E[X]\rvert^2 \geq t^2) \leq \frac{E[\lvert X-\E[X] \rvert^2]}{t^2} = \frac{\Var(X)}{t^2}.
\]
Another application of this technique are \textit{Chernoff bounds}\index{Chernoff bounds}.
For that, we take \( \varphi(x) = e^{\lambda x} \) for some \( \lambda > 0 \) and obtain
\[
    \Prob(X \geq t) = \Prob( e^{\lambda X} \geq e^{\lambda t}) \leq \frac{\E[e^{\lambda X}]}{e^{\lambda t}}.
\]

Going back to Gaussian random variables once more, we can categorize random variables by their tail behavior in relation to the Gaussian distribution.
We call a random variable $X$ \textit{sub-Gaussian}\index{sub-Gaussian!random variable}, if there exists a positive constant $C$, such that for every \( x \geq 0 \),
\[
    \Prob(\lvert X \rvert \geq x) \leq 2 \exp(-x^2/C^2).
\]
Equivalently, we can define sub-Gaussian random variables $X$ using the bound on the moment generating function
\(
    \E[e^{\lambda(X-\mu)}] \leq e^{\sigma^2 \frac{\lambda^2}{2}}.
\)








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Stochastic Processes %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Stochastic Processes}~\label{sec:stoch_processes}
% \begin{figure}[b]
%     \centering
%     \includegraphics[scale=0.9]{Screenshot 2023-11-28 151344.png}
%     \caption{ \textcolor{red}{Screenshot noch nachbauen} Examples of a random variable, random vector and random process}
%     \label{fig:Screenshot 2023-11-28 151344.png}
% \end{figure}
% 
\begin{figure}[b]
    \centering
    \input{figures/random_variable_random_vector_random_process.pgf}
    \caption{Samples drawn from a random variable, a random vector, and a random process.}
    \label{fig:random_variable_random_vector_random_process.pgf}
\end{figure}
% 
% 
\begin{definition}[Stochastic process]
    Take a probability space \((\Omega,\mathcal{A},\Prob)\) and a set of random variables \( \{ X_{t} \}_{t \in T} \), which all take values in the same measurable sample space \( (E,\mathcal{E}) \), indexed by some set $T$. 
    We call \( \{ X_{t} \}_{t \in T} \) a \textit{stochastic process}\index{random!process}.
\end{definition}
In this thesis, we will always assume that $T$ is a metric space with a group structure.
From the point of view of mappings, we have for every \( t \in T \) a measurable map
\[
    X_{t} \colon \Omega \to E,
\]
whose inverse maps $\mathcal{E}$ into $\mathcal{A}$.
Fixing a point \(  \omega \in \Omega \) in the probability space instead, we can take a different perspective and define sample paths
\begin{align*}
    X(\omega) \colon T &\to E \\*
    t &\mapsto X_{t}(\omega).
\end{align*}
But ultimately, we want to treat the stochastic process as a random variable with values in the space of functions \( E^{T} \coloneqq \{f \mid f \colon T \to E\} \).
That is,
\begin{align*}
    X \colon \Omega &\to E^{T}\\*
    w &\mapsto X(\omega).
\end{align*}
\cref{fig:random_variable_random_vector_random_process.pgf} shows an example of such random functions next to random variables and vectors.
The question arises if $X$, viewed in this way, is measurable as a map from \( (\Omega, \mathcal{A}) \) to  \( (E^{T}, \mathcal{E}^{T}) \).
As our $\sigma$-algebra \( \mathcal{E}^{T} \) we pick the $\sigma$-algebra generated by all the sets of the form \( \{ x \in E^{T} \mid x_{t} \in C \}  \) with \( t \in T \) and \( C \in \mathcal{E} \).
This is the smallest $\sigma$-algebra that makes $X$ and the projections \( \pi_{t} \colon E^{T} \to E \) with \( \pi_{t}(x)=x_{t} \) measurable~\cite[Lemma 3.2]{bovier2022stochastic}.
By the measurability of the \( X_{t} \), we have
\[
    X^{-1}(\{x \mid x_{t} \in C\}) = \{ \omega \mid X_{t}(\omega) \in C\} \in \mathcal{A}
\]
for all \( t \in T \) and \( C \in \mathcal{E} \).
Therefore 
\( X^{-1}(S)  \in \mathcal{A} \) for all $S$ from our generating set and $X$ is measurable in the desired sense.



The collection of probability distributions of the random vectors
\[
    (X_{t_{1}},\dots, X_{t_{k}})
\]
for all \( k \geq 1, t_{1}, \dots, t_{k} \in T \) is called the \textit{finite dimensional distribution}\index{finite dimensional distribution} of \( \{X_{t}\}_{t \in T} \).
We define the projections onto a finite subset \( H \subset T \) as the projections onto the vector with components in $H$
\begin{align*}
    \pi_{H} \colon E^{T} &\to E^{H}\\
    x &\mapsto (x_{h})_{h \in H}.
\end{align*}
Suppose that for each finite \( H \subset T \) there is a probability measure $\mu_{H}$ on $E^{H}$.
We say that the collection of measures \( \mu_{H}  \) is consistent if
\[
    H \subset T \text{ finite } \Leftrightarrow \mu_{H} = \mu_{T} \circ \pi_{H}^{-1}.
\]
Not every measurable stochastic process is consistent.
% We are not yet guaranteed a consistent process by the fact, that a stochastic process is measurable.
This is where the Kolmogorov extension theorem comes in.


\begin{theorem}[Kolmogorov extension theorem]~\label{thm:kolmogorov_extension_theorem}\index{Kolmogorov extension theorem}
    Given a consistent collection \( \{\mu_{H} \mid H \subset T \text{ finite}\} \) of probability measures on \( \mathbb{R}^{H} \) respectively, there exists a unique probability measure $\Prob$ on the Borel subsets of \( \mathbb{R}^{T} \) such that \( \Prob \circ \pi^{-1}_{H} = \mu_{H} \), for all finite \( H \subset T \).
    % Let $E$ be a Polish space. and let \( \mathcal{E} \coloneqq \mathcal{B}(E) \) be its Borel $\sigma$-field. Let \dots be a family of finite dimensional probability distributions on \( (E^{k}, \mathcal{E}^{k}) \) satisfying the conditions\dots. Then there exists a unique probability $P$ on \textcolor{red}{the Borel subsets of \( \mathcal{R}^{T} \)}the canonical measurable space \( (E^{T}, \mathcal{E}^{T})\) such that the coordinate process \( \{\pi_{t}\}_{t \in T} \) admits the finite distribution \dots.
\end{theorem}
We will omit the proof of this theorem and refer to standard literature such as \cite{tao2011introduction,bremaud2020probability}.
% Let us now look at some more properties of stochastic processes.
vTwo stochastic processes \( \{X(t)\}_{t \in T} \) and \( \{Y(t)\}_{t \in T'} \), defined on the same probability space, with values in \( (E,\mathcal{E}) \) and \( (E',\mathcal{E}') \) respectively, are called \textit{independent} if their $\sigma$-algebras \( \sigma(X(t); t \in T) \) and \( \sigma(Y(t); t \in T') \) are independent, so if all pairs of events, one from each of the two $\sigma$-algebras, are independent.
The probability \( \Prob_{X} \) on \( (E^{T}, \mathcal{E}^{T}) \), that is the image of $\Prob$ by \( X \colon \Omega \to E^{T} \), is called the \textit{distribution} of \( \{X(t)\}_{t \in T} \).

\begin{proposition}[\cite{bremaud2020probability}]
    For the stochatic processes \( \{X(t)\}_{t \in T} \) and \( \{Y(t)\}_{t \in T} \) to be independent, it suffices that for all \( t_{1}, \dots, t_{k} \in T \) and \( s_{1}, \dots, s_{l} \in T' \), the vectors \( (X_{t_{1}}, \dots, X_{t_{k}}) \) and \( (Y_{s_{1}}, \dots, Y_{s_{l}}) \) to be independent.
\end{proposition}
Two processes $X$ and $Y$ are said to be a \textit{version} of each other if they have the same finite dimensional distributions. 
They are said to be a \textit{modification} of each other if they are equal almost surely, that is, if \( \Prob(X_{t} = Y_{t}) = 1 \).
A measurable stochastic process \( \{X(t)\}_{t \in T} \) satisfying the condition
\[
    \E\left[ \lvert X(t) \rvert^2\right] < \infty
\]
is called a \textit{second-order} stochastic process
For such a process we can define the \textit{mean}
\[
    m(t) \coloneqq \E[X(t)]
\]
and \textit{covariance}
\[
    \Gamma(t,s) \coloneqq \Cov(X_{t},X_{s}) = \E[X(t)X(s)] - m(t)m(s).
\]
% Due to the same argument as the covariance matrix of a random vector this function is always positive semi-definite.


\begin{definition}[Gaussian Process]
    Let $T$ be an arbitrary index set. A real-valued stochastic process \( \{X_{t}\}_{t \in T} \) is called a \textit{Gaussian process}\index{Gaussian process} if for all finite \( t_{1}, \dots, t_{n} \in T \), the random vector \( (X_{t_{1}}, \dots, X_{t_{n}}) \) is Gaussian.
\end{definition}
%
\begin{theorem}[Gaussian Process]
    Let $T$ be a set and let \( C \colon T \times T \to \mathbb{R} \) define a positive-definite function,
    that is,
    \[
        \sum_{i=1}^{n} \sum_{j=1}^{n}  u_{i} u_{j} C(t_{i},t_{j}) > 0
    \]
    for all \( n \in \mathbb{N} \), \( t_{1}, \dots, t_{n} \in T \) and \( u_{1}, \dots, u_{n} \in \mathbb{R} \).
    Then there exists a unique zero mean Gaussian process with covariance $C$.
\end{theorem}
\begin{proof}
    Take an arbitrary \( n \in \mathbb{N} \) and take \( t_{1}, \dots, t_{n} \in T  \). 
    Let us construct a Gaussian vector $X$ with zero mean and covariance matrix \( \Gamma = \{C(t_{i},t_{j})\}_{1 \leq i,j \leq n} \). Since $\Gamma$ defines a positive-definite matrix, it has a Cholesky decomposition \( \Gamma = A A^{T} \). Let \( X = A Z \), where $Z$ is a vector of independent standard normal random variables. Then $X$ is a Gaussian vector with zero mean and covariance matrix $\Gamma$, as we can see from computing the characteristic function
    \[
        \varphi_{X}(u) = \E[e^{i \langle u,AZ\rangle}] = e^{-\frac{1}{2} \lVert u^{T} A \rVert^{2}}
        =e^{- \frac{1}{2} \langle u, \Gamma u \rangle}.
    \]
    To construct a Gaussian process with covariance $C$, we will use these vectors and apply \cref{thm:kolmogorov_extension_theorem}.
    For that we need to show that the set of finite dimensional distributions constructed in this way are consistent.
    As pointed out in \cite{chen2020remarks}, the projection of the Gaussian distribution on $\mathbb{R}^{n}$ with covariance matrix $\Gamma = [C(t_{i},t_{j})]_{1 \leq i,j \leq n}  \in \mathbb{R}^{n \times n}$ to the first first $n-1$ coordinates is a Gaussian distribution with covariance matrix $\Gamma = [C(t_{i},t_{j})]_{1 \leq i,j \leq n-1} \in \mathbb{R}^{(n-1)\times (n-1)}$.
    Therefore the set of finite dimensional distributions for all $n \in \mathbb{N}$ and \( t_{1}, \dots, t_{n} \in T  \) is consistent.
    And by \cref{thm:kolmogorov_extension_theorem} a zero mean Gaussian process with covariance $C$ exists and is unique. 
\end{proof}
We have seen how the Kolmogorov extension theorem can be used to construct a Gaussian process.
Of course it is also possible to construct stochastic processes with other distributions.
Markov chains would be another example. 
But Gaussian processes will suffice for our purposes, we will go into more detail about why Gaussian processes are so useful at the beginning of \cref{chap:kriging_bayes}. 
\cref{fig:gaussian_process_evaluated} shows samples drawn from a Gaussian process and a cross-section for one $x^{*} \in T$. 
This cross section illustrates, that for any given point, the paths are normally distributed.
\begin{figure}
    \centering
    \input{figures/gaussian_process_evaluated.pgf}
    \caption{Sample paths of a Gaussian process evaluated at \( x^{*} \in T \).}
    \label{fig:gaussian_process_evaluated}
\end{figure}



\begin{lemma}[Conditioned Gaussian Random Vector]~\label{lem:conditioned_gaussian_random_vector}\index{conditioned Gaussian}
    Let \( X = \begin{bmatrix}
    X_{1} \\
    X_{2}
    \end{bmatrix} \) be a Gaussian random vector with mean
    \[
        \mu = 
        \begin{bmatrix}
        \mu_{1}\\
        \mu_{2}
        \end{bmatrix}
    \]
    and covariance matrix
    \[
        \Sigma= 
        \begin{bmatrix}
        \Sigma_{11} & \Sigma_{12}\\
        \Sigma_{21} & \Sigma_{22}
        \end{bmatrix}
    \]
    Then the conditioned random vector \( X_{1} \mid X_{2} \) is also Gaussian with mean
    \[
        \bar{\mu} = \mu_{1} + \Sigma_{12} \Sigma_{22}^{-1}(a-\mu_{2})
    \]
    and covariance
    \[
        \bar{\Sigma} =  \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}.
    \]
\end{lemma}


\begin{proof}
    This is a well known result.
    We will follow the proof outlined in~\cite{bishop2006pattern}.
    Let \( n_{1} \) and \( n_{2} \) be the dimensions of \( X_{1} \) and \( X_{2} \) respectively.
    Further, let \[ \Sigma^{-1} = \Lambda = \begin{bmatrix}
    \Lambda_{11} & \Lambda_{12}\\
    \Lambda_{21} & \Lambda_{22}
    \end{bmatrix} \]
    be the inverse of the covariance matrix. We note that $\Lambda$ is symmetric, since the covariance matrix is also symmetric.
    One possible path to the solution is to compute the conditional distribution \( p(X_{1} \mid X_{2}) \) explicitly.
    This is done in~\cite{soch2024statproofbook}.
    We will take a different approach.
    Note that due to the chain rule of probability, the conditional distribution is given by
    \[
        p(X_{1} \mid X_{2}) = \frac{p(X_{1},X_{2})}{p(X_{2})} = \frac{p(X)}{p(X_{2})}.
    \]
    If we fix $X_{2}$, this distribution is a scaled version of the joint distribution \( p(X) \).
    We will use this fact, and the fact that Gaussian distributions are uniquely determined by the quatratic form in the exponent of the density function
    \begin{equation}
        \label{eq:gaussian_exponent}
        -\frac{1}{2} (X-\mu)^{T} \Sigma^{-1} (X-\mu)
    \end{equation}
    to derive the conditional distribution.
    For that purpose, we want to show that the exponent of the conditional distribution is a quadratic form in $X_{1}$.
    Spreading the multiplication into the block matrix components \eqref{eq:gaussian_exponent} yields
    \begin{equation}\label{eq:conditioned_gaussian_random_vector}
        \begin{aligned}
            -\frac{1}{2}(X-\mu)^{T} \Sigma^{-1} (X-\mu) &= \\
            -\frac{1}{2} ( X_{1} - \mu_{1})^{T}\Lambda_{11}&(X_{1}-\mu_{1}) 
            -\frac{1}{2} ( X_{1} - \mu_{1})^{T}\Lambda_{12}(X_{2}-\mu_{2})\\
            -\frac{1}{2} ( X_{2} - \mu_{2})^{T}\Lambda_{21}&(X_{1}-\mu_{1})
            -\frac{1}{2} ( X_{2} - \mu_{2})^{T}\Lambda_{22}(X_{2}-\mu_{2}) \\
        \end{aligned}    
    \end{equation}
    To show that this is a quadratic form in $X_{1}$, we will use a technique called \textit{completing the square}.
    A general Gaussian distribution with mean $\mu$ and covariance $\Sigma$ has an exponent of the form
    \begin{equation}\label{eq:general_gaussian_exponent}
        -\frac{1}{2} (x-\mu)^{T} \Sigma^{-1} (x-\mu) = -\frac{1}{2} x^{T} \Sigma^{-1} x + x^{T} \Sigma^{-1} \mu - \frac{1}{2} \mu^{T} \Sigma^{-1} \mu.
    \end{equation}
    Here, we have a part that is quadratic in $x$, a part that is linear in $x$ and a part that is constant in $x$.
    To bring \eqref{eq:conditioned_gaussian_random_vector} into this form, we can thus collect the second order terms in $X_{1}$ from \eqref{eq:conditioned_gaussian_random_vector} and compare them to the second order terms of $x$ in \eqref{eq:general_gaussian_exponent} to derive the covariance matrix. And collect the first order terms in $x_{1}$ to calculate the mean.
    
    Collecting all the second order terms in $X_{1}$ from \eqref{eq:conditioned_gaussian_random_vector}, we get
    \[
        -\frac{1}{2} X_{1}^{T} \Lambda_{11} X_{1}.
    \]
    Thus we can immediately conclude \( \bar{ \Sigma} = \Lambda_{11}^{-1} \).
    Similarly we can collect all the first order terms in $X_{1}$ from \eqref{eq:conditioned_gaussian_random_vector} and get
    \[
        X_{1}^{T}(\Lambda_{11}\mu_{1}-\Lambda_{12}(X_{2}-\mu_{2})),
    \]
    where we have used the symmetry of $\Lambda$.
    Due to \eqref{eq:general_gaussian_exponent}, the coefficient of this expression must be equal to $\bar{\Sigma}^{-1} \bar{\mu}$.
    So, multiplying by \( \bar{\Sigma} \), we get
    \begin{align*}
        \bar{\mu} &= \bar{\Sigma}(\Lambda_{11}\mu_{1}-\Lambda_{12}(X_{2}-\mu_{2})) \\
        &= \mu_{1} - \Lambda_{11}^{-1}\Lambda_{12}(X_{2}-\mu_{2}) 
    \end{align*}
    We can ignore the constant terms in \eqref{eq:conditioned_gaussian_random_vector} and \eqref{eq:general_gaussian_exponent}, since they are only a scaling factor for the density function. We have thus shown, that the exponent of the conditional distribution is a quadratic form in $X_{1}$. Therefore the conditional distribution is Gaussian.
        
    The only thing missing now is to calculate the inverses of our block matrices in $\Lambda$, in order to get an explicit formula for \( \bar{\mu} \) and \( \bar{\Sigma} \).
    A Matrix inversion Lemma~\cite{lu2002inverses} for $2 \times 2$ block matrices states that
    \[
    \begin{bmatrix} A & B \\ C & D \end{bmatrix}^{-1} = \begin{bmatrix} (A-BD^{-1}C)^{-1} & -(A-BD^{-1}C)^{-1}BD^{-1} \\ -D^{-1}C(A-BD^{-1}C)^{-1} & D^{-1}+D^{-1}C(A-BD^{-1}C)^{-1}BD^{-1} \end{bmatrix},
    \]
    given, that all the inverses exist.
    Applying this to our case, we get
    \begin{align*}
        \Lambda_{11}^{-1} &= \Sigma_{11}^{-1} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21},\\
        \Lambda_{12} &= -(\Sigma_{11}- \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}) \Sigma_{12} \Sigma_{22}^{-1}.
    \end{align*}
    Plugging these into the expressions for $\bar{\mu}$ and $\bar{\Sigma}$ gives the formulas
    \begin{align*}
        \bar{\Sigma} &= \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21},\\
        \bar{\mu} &= \mu_{1} + \Sigma_{12} \Sigma_{22}^{-1}(X_{2}-\mu_{2}). \qedhere
    \end{align*}
\end{proof}





\begin{proposition}[Conditional Gaussian Processes]
    Take a Gaussian process \( \{X(t)\}_{t \in T} \) with mean function \( m(t) \) and covariance function \( \Gamma(t,s) \). Conditioning on the event \( X(t_{1}) = x_{1}, \dots, X(t_{n}) = x_{n} \) gives another Gaussian process.
\end{proposition}
\begin{proof}
    This is just an application of \cref{lem:conditioned_gaussian_random_vector} and \cref{thm:kolmogorov_extension_theorem}. \qedhere
\end{proof}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Random Fields %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 


\section{Random Fields}~\label{sec:random_fields}
% 
A lot of the study of stochastic processes is concerned with random variables indexed by time.
\textit{Random fields}\index{random!field} are stochastic processes on a more general topologial index set \(T\). For our purposes, we will just look at \(n\)-dimensional real vectors. An example of a random field on \( [0,1]^2 \) is given in \cref{fig:random_field_single}.
But other index sets, like sets of functions are possible.

\begin{wrapfigure}{r}{0.33\textwidth}
    % \input{figures/random_field.pgf}
    \vspace{-15pt}
    \includegraphics[width=0.33\textwidth]{figures/random_field-img0.png}
    \caption{A random field.}
    % \vspace{-5pt}
    \label{fig:random_field_single}
\end{wrapfigure}
To capture the spacially correlated structure of random fields, we need to define a \textit{covariance function}\index{covariance function}, often also referred to as a covariance kernel.
Such a function gives the covariance of the values of a random field $X$ at points $x,y$
\begin{align*}
    C(x,y) &\coloneqq \Cov(X_{x},X_{y})\\
    &= \E\left[(X_{x} -\E[X_{x}])(X_{y} -\E[X_{y}])\right].
\end{align*}
Arbitrary functions are not admissable, a function is a valid covariance function if and only if it is positive semi-definite, i.e.
\[
    \sum_{i=1}^{n} \sum_{j=1}^{n} w_{i} C(x_{i},x_{j}) w_{j} \geq 0
\]
for all $x,y \in T$, $n \in \mathbb{N}$ and weights $w \in R^{n}$
It is clear to see, that this is a necessary condition, since 
\( \Var(\sum_{i=1}^{n} w_{i}X_{x_{i}}) = \sum_{i=1}^{n} \sum_{j=1}^{n} w_{i} C(x_{i},x_{j}) w_{j} \) needs to be non-negative. 
The fact that every positive semidefinite function defines a valid covariance function is less obvious and is a conclusion the following \cref{thm:bochner}.

\begin{theorem}[Bochner Theorem]~\label{thm:bochner}\index{Bochner Theorem}
    ~\cite[Thm. 19]{bochner1933monotone}
    A continous stationary function \( \Gamma(s,t)= C(\lvert s-t \rvert) \) is
    positive definite (i.e. a covariance function) if and only if it can be represented as
    \[
        C(t) =  \int e^{ 2 \pi i \omega t} \dx[\mu](\omega),
    \] 
    where $\mu$ is a finite positive measure.
    If $\mu$ has a density \( S(s) \), then $S$ is called the \textit{spectral density} or \textit{power spectrum} of $C$, and $C$ and $S$ are Fourier duals, that is
    \[
        C(t) = \int S(s) e^{2 \pi i \langle t, s \rangle} \dx[s]
    \]
    and
    \[
        S(s) = \int C(t) e^{-2 \pi i \langle t, s \rangle} \dx[t].
    \]
\end{theorem}
This form of a covariance function can then be used to construct a random field. For the details we refer to \cite[p.84]{cressie1993statistics}.
%
The following examples of covariance functions are not given in terms of two variables from the index set $T$, but in terms of the distance between two points \( s,t \in T \). A covariance $\Gamma$ for example might be charactercized by a function $C$ with \( \Gamma(s,t) = C(\lvert s-t \rvert) \). The edge cases of perfect covariance and zero covariance everywhere but the origin lead to random fields that are the same everywhere and white noise respectively.
Given a correlation length scale $\rho$ and variance $\sigma$, the  \textit{cosine covariance function}\index{covariance function!cosine} is defined as
\[
    C_{\cos}(d) =\sigma^2 \cos\left(2 \pi \frac{d}{\rho}\right).
\]
This function was used to generate the random field on the right in \cref{fig:random_fields_intro.png}.
The \textit{squared exponential covariance function}\index{covariance function!squared exponential} is defined as
\[
    C_{SE}(d) = \sigma^2 \exp\left(-\frac{d^2}{\rho^2}\right).
\]
This covariance function is infinitely differentiable, therefore generates very smooth random fields \cite{adler2007random}.
A less smooth, and hence often more useful covariance function is the \textit{Mat√©rn covariance function}\index{covariance function!Mat√©rn}, defined as
\[
    C_{\nu}(d) = \sigma^2 \frac{2^{1-\nu}}{\Gamma(\nu)} \left( \sqrt{2\nu} \frac{d}{\rho} \right)^{\nu} K_{\nu} (\sqrt{2\nu} \frac{d}{\rho}),
\]
where $\Gamma$ is the gamma function, \( K_{\nu} \) is the modified Bessel function of the second kind and $\nu$ is a positive smoothness parameter of the covariance function.
Its Fourier transformation is given by
\[
    \hat{C_{\nu}}(z) =  \frac{\Gamma(\nu+d/2)}{\pi^{d/2}\Gamma(\nu)}\frac{\alpha^{d}}{(1+\alpha^2 z^2)^{\nu+d/2}},
\] 
for \( z \in \mathbb{R} \)~\cite[Eq. 11.4.44]{abramowitz1968handbook}. 
% \begin{example}[Cosine Covariance]
%     Given a correlation length scale $\rho$ and variance $\sigma$, the cosine covariance function is defined as
%     \[
%         C_{\cos}(d) =\sigma^2 \cos(2 \pi \frac{d}{\rho}).
%     \]
%     This function was used to generate the image on the right in \cref{fig:random_fields_intro.png}
% \end{example}
% \begin{example}[Squared Exponential Covariance Function]
%     The squared exponential covariance function is defined as
%     \[
%         C_{SE}(d) = \sigma^2 \exp(-(\frac{d}{\rho})^2),
%     \]
%     with distance $d$, variance $\sigma$ and length scale $\rho$.  
% \end{example}
% \begin{example}[Mat√©rn Covariance Function]
%     The Mat√©rn covariance function is defined as
%     \[
%         C_{\nu}(d) = \sigma^2 \frac{2^{1-\nu}}{\Gamma(\nu)} \left( \sqrt{2\nu} \frac{d}{\rho} \right)^{\nu} K_{\nu} (\sqrt{2\nu} \frac{d}{\rho}),
%     \]
%     where $\Gamma$ is the gamma function, \( K_{\nu} \) is the modified Bessel function of the second kind and $\rho$ and $\nu$ are positive parameters of the covariance.
%     It has Fourier transformation
%     \[
%         \hat{C_{\nu}}(z) =  \frac{\Gamma(\nu+d/2)}{\pi^{d/2}\Gamma(\nu)}\frac{\alpha^{d}}{(1+\alpha^2 z^2)^{\nu+d/2}}
%     \] 
%     for \( z \geq 0 \). \textcolor{red}{Cite 11.4.44. \cite[11.4.44]{abramowitz1968handbook}}
% \end{example}
\begin{figure}[ht]
    \centering
    \input{figures/covariance_kernels_plot.pgf}
    \caption{Different Mat√©rn and squared exponential covariance kernels.}
    \label{fig:covariance_kernels_plot}
\end{figure}
% \textcolor{red}{Next sentence can go? Or at least explain concentration of measure}
% Another benefit of the Mat√©rn kernel is that it does not have the same problems of concentration of measure for high dimensional inputs that the squared exponential kernel has (Fastfood: Le, Sarlos, Smola, ICML 2013)
% 
% Let us drop the mathematical rigour for a moment to give an intuition for where this formula comes from. (Write down the stuff from the stackexchange post about solution of SDE, how the radial basis function might be too smooth for some cases.) Now let us resume with the rigerous mathematical theory again, lest we make the scary descent into the lair of physicists and applied scientists complete.

% \begin{example}[Power law]
%     Given \(P(k)=k^{-\alpha}\), we get a covariance that is self similar in a fractal kind of way, since power law functions are self similar at scales (wikipedia article for power law functions has an article about this)
% \end{example}


\begin{wrapfigure}{R}{0.33\textwidth}
    \vspace{-20pt}
    \input{figures/random_field_anisoptropic.pgf}
    \caption{An anisotropic random field.}
    % \vspace{-10pt}
    \label{fig:ranom_field_anisotropic}
\end{wrapfigure}


% \begin{example}[White noise]
%     If the covariance is zero, we get white noise. If the covariance is one, the whole space has one degree of freedom so to speak and will have one random color.
% \end{example}
% We have a result by Loeve 
% \begin{theorem}[Loeve]
%     $k$ corresponds to the covariance of a Gaussian process if and only if $k$ is a positive semi-definite function, i.e.
%     \[
%         \sum_{i=0}^{n} \sum_{j=0}^{n} \alpha_{i} \alpha_{j} k(x_{i},x_{j}) \geq 0
%     \]
%     for all \( n \in \mathbb{N}, x_{i} \in \mathcal{X}, \alpha_{i} \in \mathbb{R} \).
% \end{theorem}

\begin{definition}[Strict Stationarity]\index{stationarity!strict}

    A stochastic process \( \{X(t)\}_{t \in T} \) is called \textit{strictly stationary} if for all \( k \geq 1 \), all \( (t_{1}, \dots t_{k}) \) in \( T^{k} \), the probability distribution of the random vector 
    \[
        (X(t_{1}+h), \dots, X(t_{k}+h))
    \]
    is independent of \( h \in T \), with \( h \in T \) such that \( t_{1}+h, \dots, t_{k}+h \in T\).
\end{definition}
%
\begin{definition}[Second Order Stochastic Process]\index{second order process}
    A measureable stochastic process \(\{X_{t}\}\) satisfying the condition
    \[
        \E\left[ \lvert X_{t} \rvert^2 \right] < \infty
    \]
    for all $t \in T$ is called a \textit{second order} stochastic process
\end{definition}
%
\begin{definition}[Weak Stationarity]\index{stationarity!weak}
    A second order stochastic process \(\{X_{t}\}\) with mean \(\mu_{X}(t)\) and covariance \( \Gamma_{X}(t,s) \) at \( t,s \in T \) is called \textit{weakly stationary}, if \( \mu_{X} \) is constant and \( \Gamma_{X}(t,s) \) is a function of \( t-s \) only.
\end{definition}

A process is called \textit{isotropic}\index{isotropy} if its covariance function \( \Gamma(t,s) \) is only a function of the distance \( \lvert t-s \rvert \). An example of when this condition is not met is shown in \cref{fig:ranom_field_anisotropic}

\begin{theorem}[Stationarity Equivalence]\index{stationarity!equivalence}
    For Gaussian processes on \( T = \mathbb{R}^{d} \), $d \in \mathbb{N}$ the concepts of weak and strict stationarity coincide.
\end{theorem}

\begin{proof}
    Strict stationarity implies weak stationarity trivially.
    For the other direction note that the mean and covariance functions completely characterize the finite dimensional distributions, since these are normal distributions.
\end{proof}
% (https://gpss.cc/gpss21/slides/Heinonen2021.pdf Page 10).
% \textcolor{red}{Do I want the following sentence?}
% In many physical domains random fields arise as sums of random waves. Their spacial interaction is understandably better characterized in the frequency domain. The following spectral theorem gives some insights into the connection between covariance functions and spectral densities. 
\begin{figure}[b]
    \centering
    \input{figures/samples_drawn_Matern_nu_05_d_02.pgf}
    \input{figures/samples_drawn_Matern_nu_15_d_02.pgf}
    \input{figures/samples_drawn_Matern_nu_25_d_02.pgf}
    \caption{Samples drawn from Mat√©rn processes with different smoothness parameters.}
    \label{fig:samples_matern_gaussian_kernel}
\end{figure}



\begin{proposition}
    The Mat√©rn covariance function with length parameter $\omega$ and smoothness parameter $\alpha$ is positive definite.
    Thereby it is a valid covariance function.
\end{proposition}
\begin{proof}
    We can use the Fourier transformation of the Mat√©rn covariance function, which is given by \( \xi \mapsto \frac{1}{(\lvert \xi \rvert^2+\omega^2)^{\alpha}} \).
    For $n \in \mathbb{N}$ and $z_{1}, \dots ,z_{n} \in \mathbb{C}$ we have
\begin{align*}
    \sum_{j=1}^{n} \sum_{k=1}^{n} z_{j}\overline{z_{k}} C(t_{j} -t_{k}) &=
    \sum_{j=1}^{n} \sum_{k=1}^{n} z_{j}\overline{z_{k}} \int_{\mathbb{R}^{d}} e^{i \xi t_{j}} e^{-i \xi t_{j}} \frac{1}{(\lvert \xi \rvert^2+\omega^2)^{\alpha}}\dx[\xi]\\
    &=\int_{\mathbb{R}^{d}}  \sum_{j=1}^{n} \sum_{k=1}^{n} z_{j} e^{i \xi t_{j}} \overline{z_{k}e^{i \xi t_{j}}}\frac{1}{(\lvert \xi \rvert^2+\omega^2)^{\alpha}}\dx[\xi]
    \\
    &= \int_{\mathbb{R}^{d}} \left| \sum_{j=1}^{n}  z_{j} e^{i \xi t_{j}} \right|^2 \frac{1}{(\lvert \xi \rvert^2+\omega^2)^{\alpha}}\dx[\xi] \geq 0.
\end{align*}
Therefore the Mat√©rn covariance function is positive definite and thereby a valid covariance function.
\end{proof}
% We will briefly mention a result ensuring the continuity of random fields in certain scenarios. 
% The following theorem is analogous to Kolmogorov's continuity theorem for one dimensional stochastic processes~\cite[Thm. 5.2.3]{bremaud2020probability}.
% \begin{theorem}[Random Field Continuity Theorem]
%     ~\cite[Thm. 2.8]{potthoff2009sample}
%     Let \( (T,d) \) be a well seperable metric space (i.e. \dots), and let \( \{X_{t}\}_{t \in T} \) be a random field, so that
%     \
%         \sum_{n=1}^{\infty} \lvert \pi_{n} \rvert q(\delta_{n}) < \infty
%     \]
%     and 
%     \[
%         \sum_{n=1}^{\infty} r(\delta_{n}) < \infty
%     \]
%     and for all \( s,t \in T \) with \( d(s,t) < \rho \)
%     \[
%         \Prob \left( \lvert X_{s}-X_{t} \rvert \geq r(d(s,t)) \right) \leq q(d(s,t)).
%     \]
%     Then \( \{ X_{t} \}_{t \in T} \) has a locally uniformly sample continuous modification. If in addition \( (T,d) \) is uniformly well seperable, the modification can be chosen such that it is uniformly sample continuous.
%     \textcolor{red}{There's a lot of explaining left to do here. Do I want this theorem or the one about H√∂lder continuity?}
% \end{theorem}
The smoothness of the Gaussian process $f$ is determined by the smoothness of the covariance function $C$.
A process $f$ is continuous in the mean square sense at $x^{*} \in T$, i.e. $\E[\lvert f(x^{*}) -f(x_{k}) \rvert^2] \to 0$ as $x_{k} \to x^{*}$, if and only if the covariance function $C(x,x')$ is continuous at the point $x=x'=x^{*}$ \cite{williams2006gaussian}.
If for a stationary processes $f$ the $2n$-th order partial derivative of the covariance function \( \partial^{2n}C(x)/\partial^{2}_{x_{i1}, \dots, x_{in}} \) exists and is finite at $x=0$, then the $n$-th order partial derivative \( \partial^{n} f(x)/ \partial_{x_{i1}, \dots, x_{in}} \) exists for all $x \in \mathbb{R}^{d}$ as a mean square limit \cite{williams2006gaussian}.
As we can see in \cref{fig:covariance_kernels_plot}, the Mat√©rn covariance kernels for different parameters are not differentiable at the origin. But we still get H√∂lder continuity to varying degrees depending on the parameter $\nu$, as will be explored closer in \cref{chap:bound}.
\cref{fig:samples_matern_gaussian_kernel} shows samples drawn from Mat√©rn processes with different smoothness parameters.
The bigger the parameter $\nu$, the smoother the random field. 
The limit $\nu \to \infty$ yields the squared exponential covariance function~\cite{porcu2023mat}.
Another result dealing with the continuity of random fields is the following proposition.
\begin{proposition}[Multiparameter Kolmogorov Continuity Theorem]
    Let \( X = \{  X_{t} \mid t \in [0,1]^{N} \} \) be a real-valued stochastic process. Suppose there exist positive constants $\beta,K$ and $\delta$ such that
    \[
        \E[\lvert X_{s} - X_{t} \rvert^{\beta}] \leq K \lVert s-t \rVert^{N+\delta}
    \]
    for all $s,t \in [0,1]^{N}$.
    Then $X$ has a modification which is uniformly H√∂lder continuous on $[0,1]^{N}$ of all orders $< \frac{\delta}{\beta}$ 
\end{proposition}
For a proof of this statement, we refer to \cite{xiao2010uniform}.    




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Concentration %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Concentration}






This section deals with the concentration\index{concentration} of stochastic processes around their mean.
We are looking to generalize the concept of concentration of measure for random variables introduced in \cref{sec:basics} to stochastic processes.
\begin{definition}[Sub-Gaussian Process]
    A  process \(\{X_{t}\}t \in T\) is \textit{sub-Gaussian}\index{sub-Gaussian!process} with respect to a metric\(d\) on \(T\) if
    \[
        \E\left[e^{\lambda(X_{t}X_{\tilde{t}})}\right] \leq e^{\frac{\lambda^2 d(t, \tilde{t})^2}{2}} 
    \]
    for all \(t, \tilde{t} \in T\) and \(\lambda \in \mathbb{R}\).    
\end{definition}
Similar to sub-Gaussian random variables, this statement is equivalent~\cite[p.134]{wainwright2019high}
to the tail bound
\[
    \Prob( \lvert X_{\theta} - X_{\tilde{\theta}} \rvert \geq t) \leq 2 \exp\left(-\frac{t^2}{2 d_{X}(\theta, \tilde{\theta})^2}\right).
\]
% \textcolor{red}{
% Here we can put some useful tools of sub-gaussian processes motivated by inequality before 8.44 in HDP Book on page 229 and the very last statement of that same proof.}
% 
% 
For the following theorem we need one property.
\begin{definition}[Separable Process]
    A stochastic process \( \{ X_{t} \}_{t \in T} \) is called \textit{separable} if there exists a countable subset \( T_{0} \subset T \) and a subset \( \Omega_{0} \subset \Omega \) with \( \Prob(\Omega_{0}) = 0 \), such that for all \( \omega \in \Omega_{0}\), \( t \in T \) and \( \varepsilon>0, \)
    \[
        X_{t}(\omega) \in \overline{\{ X_{s}(\omega) \mid s \in T_{0} \cap B_{d}(t,\varepsilon) \}},
    \]
    where \( B_{d}(t,\varepsilon) \) is the ball of radius \( \varepsilon \) around \( t \) with respect to the metric \( d \).
\end{definition}
% All stochastic processes we will work with are seperable \textcolor{red}{ because of the continuity of the covariance function? Because the index set is seperable?}
\begin{proposition}
    ~\label{prop:concentration_ineq}
    \cite[Prop. 2.1.12]{gine2021mathematical}
    A process \( \{ X_{t} \}_{t \in T} \) on \( (T,d_{X}) \), where \( d_{X}(s,t)^2 = \E\left[(X_{s}-X_{t})^2\right]\) is the canonical distance, has a seperable version if and only if the pseudo-metric space \( (T,d_{X}) \) is separable.
\end{proposition}
\begin{proposition}
    \cite[Thm. 2.1.20]{gine2021mathematical}
    Let \( \{ X_{t} \}_{t \in T} \) be a seperable centered Gaussian process such that
    \[
        \Prob(\sup_{t \in T} \lvert X(t) \rvert < \infty ) > 0.
    \]
    Let $\Psi$ be an even, convex, measurable function, nondecreasing on $[0,\infty)$. Let $g$ be $\mathcal{N}(0,1)$. 
    Then \(\sigma(X) \coloneqq \sup_{t \in T} \E[X_{t}^2]^{1/2} < \infty\) 
    and \( \E[\sup_{t \in T} \lvert X_{t} \rvert] < \infty \).
    Further, the following inequalites hold:
    \[
        \E\left[\Psi \left( \sup_{t \in T} \lvert X_{t}\rvert - \E \left[\sup_{t \in T} \lvert X_{t}\rvert\right] \right)\right] 
        \leq \E\left[ \Psi \left( \frac{\pi}{2} \sigma g \right) \right]
    \]
    and
    \[
        \Prob\left( \left\lvert\sup_{t \in T} \lvert X_{t}\rvert - \E \left[\sup_{t \in T} \lvert X_{t}\rvert\right]  \right\rvert > u \right)
        \leq 2 e^{-(Ku^2/2\sigma^2)},
    \]
    where \( K = \frac{1}{\pi^2} \).
    
\end{proposition}


% Another concentration result that requires almost sure continuity \textcolor{red}{Define?}
% \textcolor{red}{Leave out this second proposition?}
% \begin{proposition}
%     \cite[Prop. 3.19]{massart2007concentration}
%     Let \( \{ X_{t} \}_{t \in T} \) be an almost surely continous centered Gaussian process on the totally bounded \( (T,d) \), letting \( \sigma>0 \) be defined as
%     \[
%         \sigma^2 = \sup_{t \in T} \E[X_{t}^2]
%     \]
%     and $Z$ denote either
%     \( \sup_{t \in T} X_{t} \) or \( \sup_{t \in T} \lvert X_{t} \rvert \).
    
%     Then for every \( \lambda \in \mathbb{R} \)
%     \[
%         \E[\exp\left(\lambda \left( Z- \E[Z]t \right)\right)] \leq e^{\frac{\lambda^2 \sigma^2}{2}},
%     \]
%     leading to the tail bound
%     \[
%         \Prob(Z - \E[Z] \geq \sigma \sqrt{2x}) \leq e^{-x}
%     \]
%     and
%     \[
%         \Prob(\E[Z] - Z \geq \sigma \sqrt{2x}) \leq e^{-x}
%     \]
%     for all positive $x$.


    
    
% \end{proposition}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Chaining %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Chaining}~\label{sec:chaining}
Another important characterization of a stochastic process is its magnitute
\[
    \E\left[\sup_{t \in T} X_{t}\right].
\]
We will derive bounds on this quantity by using a technique called chaining\index{chaining}.
Directly analyzing the stochastic process for uniform bounds can be challenging.
The process of chaining involves using information about the geometry of the space \((T,d_{X})\) to derive uniform bounds on the stochastic process, where 
\[ d_{X}(s,t) = \E\left[(X_{s}-X_{t})^2\right]^{1/2} \] 
is the \textit{canonical metric} induced by the stochastic process\index{canonical metric}.
We already briefly used this metric in the last section.
It is in general not a metric but only a pseudo-metric, since it is not necessarily positive definite.
The canonical metrix can also be reformulated in terms of covariances, for stationary processes in terms of the covariance function \(C\).
Take arbitrary \( s,t \in T \). Then
\begin{align*}
    d(s,t)^2 &= \Var(X_{s}-X_{t}) \\
    &= \Var(X_{s}) + \Var(X_{t}) - 2 \Cov(X_{s},X_{t}) \\
    &= 2(C(0)-C(\lvert s-t \rvert)).
\end{align*}

The process of chaining is usually done by constructing a sequence of finite sets \(T_n\) such that each set \(T_{n+1}\) refines the previous set \(T_n\). 
The elements of each set \(T_n\) are chosen such that they cover the index set \(T\) as closely as possible with respect to the metric \(d_{X}\).
As \(n\) increases, the set \(T_n\) becomes a better and better approximation of \(T\).
Once we have our sequence of chains \(T_n\), we can then study the behavior of the stochastic process over each chain and ultimately derive bounds of the process over the original index set \(T\).
%
\begin{definition}[Covering number]\index{chaining!covering number}
    A $\delta$-cover of a set $T$ with respect to a metric $d$ is a set \( \{ t_{1},\dots, t_{N} \} \subset T \), such that for each \( t \in T \), there exists some \( i \in \{ 1, \dots, N \} \) such that \( d(t,t_{i}) \leq \delta \). The $\delta$-covering number \( \mathcal{N}(T,d,\delta) \) is the cardinality of the smallest $\delta$-cover.
\end{definition}
%
With this first notion of geometric complexity established, we will get to an important result of the chaining technique, Dudley's integral inequality.
\begin{theorem}[Dudley's integral inequality]\label{thm:dudley_int_ineq}\index{chaining!Dudley's integral inequality}
    Let \((X_{t})_{t \in T}\) be a mean zero sub-Gaussian process with respect to the canonical distance \(d_{X}\).  
    Define \( D = \sup_{t,\widetilde{t}} d_{X}(t,\widetilde{t}) \).
    Then for any \( \delta \in (0,D] \), we have
    \[
        \E\left[\sup_{s,t \in T}(X_{s}-X_{t})\right] \leq 2 \E \Biggl[ \sup_{\substack{\gamma,\gamma' \in T \\ d_{X}(\gamma,\gamma') \leq \delta}} (X_{\gamma}- X_{\gamma'}) \Biggr] + 32 \int_{\delta/4}^{D} \sqrt{ \log \mathcal{N}(T,d_{X},u)} \dx[u]. 
    \]
    
\end{theorem}

\begin{proof}
We follow the proof outlined in~\cite[p. 140]{wainwright2019high}.
Let \( U = \{ t_{1}, \dots, t_{N} \} \) be a minimal $\delta$-covering set of $T$ and for each integer \( m=1,2, \dots, L \), let $U_{m}$ be a minimal \( \varepsilon_{m}= D 2^{-m} \) covering set of $U$ in the metric $d_{X}$, where we allow any element of $T$ to be used. Here we define $L$ as the smallest integer with \( U_{L}=U \).
For the chaining setup, define the projections \( \pi_{m} \colon U \to U_{m} \) by
\[
    \pi_{m}(t) = \argmin_{\beta \in U_{m}} d_{X}(t,\beta)
\]
for \( m=1, \dots, L \), so that \( \pi_{m}(t) \) is the best approximation of \( t \in U \) from the set \( U_{m} \).
We start from the finest covering $U_{L}=U$ and recursively construct a sequence with \( \gamma^{L} = t \) and \( \gamma^{m-1} = \pi_{m-1}(\gamma^{m}) \) for
\( m= L,L-1, \dots, 2 \).
This lets us construct the telescopic sum
\[
    X_{t}-X_{\gamma^{1}} = \sum_{m=2}^{L} (X_{y^{m}}- X_{\gamma^{m-1}}),
\]
therefore
\[
    \lvert X_{t}-X_{\gamma^{1}} \rvert \leq \sum_{m=2}^{L} \max_{\beta \in U_{m}} \lvert X_{\beta}- X_{\pi_{m-1}(\beta)} \rvert.
\]

Given any other $\widetilde{t}$, we can define the sequence \( \{ \widetilde{\gamma}^{1}, \dots, \widetilde{\gamma}^{L} \} \) and derive an analogous bound for \( \lvert X_{\widetilde{t}} - X_{\widetilde{\gamma}^{1}} \rvert \).
Combining the two, we have
\begin{align*}
    \lvert X_{t} - X_{\widetilde{t}} \rvert &= 
    \lvert X_{\gamma^{1}} - X_{\widetilde{\gamma}^{1}} + (X_{t} - X_{\gamma^{1}}) + (X_{\widetilde{\gamma}^{1}} - X_{\widetilde{t}}) \rvert \\
    &\leq \lvert X_{\gamma^{1}} - X_{\widetilde{\gamma}^{1}} \rvert + \lvert X_{t} - X_{\gamma^{1}} \rvert + \lvert X_{\widetilde{\gamma}^{1}} - X_{\widetilde{t}} \rvert.
\end{align*}
Taking maxima over all $\widetilde{t}$ and $t$ yields
\[
    \max_{t, \widetilde{t} \in U} \lvert X_{t} - X_{\widetilde{t}} \rvert \leq \max_{\gamma, \widetilde{\gamma} \in U_{1}} \lvert X_{\gamma}-X_{\widetilde{\gamma}}\rvert + 2 \sum_{m=2}^{L} \max_{\beta \in U_{m}} \lvert X_{\beta}- X_{\pi_{m-1}(\beta)} \rvert.
\]
We first upper bound the finite maximum over $U_{1}$ , which has \(N(\frac{D}{2}) \coloneqq \mathcal{N}(T,d_{X},\frac{D}{2}) \) elements. 
Because the process is sub-Gaussian, so are the increments \( X_{t} - X_{\widetilde{t}} \) with parameter at most \( d_{X}(t, \widetilde{t})  \leq D\). 
Now we can apply a known bound for the maxima of \( N(\frac{D}{2}) \) sub-Gaussian random variables~\cite[p. 53]{wainwright2019high}, namely
\[
    \E\left[ \max_{\gamma, \widetilde{\gamma} \in U_{1}} \lvert X_{\gamma} - X_{\widetilde{\gamma}} \rvert \right] \leq 2 D \sqrt{\log N(D/2)}.
\]
Similarly, for each \( m = 2,3, \dots, L \), the set \( U_{m} \) has \( N(D 2^{-m}) \) elements, and \( \max_{\beta \in U_{m}} d_{x}(\beta, \pi_{m-1}(\beta)) \leq D 2^{-(m-1)} \). Therefore
\[
    \E \left[ \max_{\beta \in U_{m}} \lvert X_{\beta}- X_{\pi_{m-1}(\beta)} \rvert \right] \leq 2 D 2^{-(m-1)} \sqrt{\log N(D 2^{-m})}.
\]
Combining the two pieces, we conclude
\[
    \E \left[ \max_{t, \widetilde{t} \in U} \lvert X_{t} - X_{\widetilde{t}} \rvert \right] \leq 4 \sum_{m=1}^{L} D 2^{-(m-1)} \sqrt{\log N(D 2^{-m})}.
\]
Since the covering number \( N(t) \) is non-increasing in \( t \), we have
\[
    D 2^{-(m-1)}\sqrt{\log N(D 2^{-m})} \leq 4 \int_{D 2^{-(m+1)}}^{D 2^{-m}} \sqrt{\log N(u)} \dx[u].
\]
Here we used the fact, that for non-increasing $f$, we have
\[
    \frac{x}{2} = \int_{x/2}^{x} 1 \dx[u]  \leq \int_{x/2}^{x} \frac{f(u)}{f(x)} \dx[u],
\]
implying
\[
    2x f(x) \leq 4 \int_{x/2}^{x} f(u) \dx[u].
\]
Therefore we can put the all integral boundaries together and get 
\begin{equation}\label{eq:dudley_bound_on_maxima_U}
    2 \E\left[\max_{t,\widetilde{t} \in U} \lvert X_{t} - X_{\widetilde{t}} \rvert\right] \leq 32 \int_{\delta/4}^{D}  \sqrt{\log \mathcal{N}(T,d_{X},u)} \dx[u].
\end{equation}
We are close to the desired result, but we still need to get rid of the restriction to the finite set $U$.
Because $U$ is a $\delta$-cover of $T$, we can find for any \( t \in T \) some $t_{i} \in U$, such that \( d(t,t_{i})  \leq \delta \). Therefore, fixing any $t_{1} \in U$,
\begin{align*}
    X_{t}-X_{t_{1}} &= (X_{t}-X_{t_{i}}) + (X_{t_{i}}-X_{t_{1}})\\
    &\leq \sup_{\substack{\gamma,\gamma' \in T \\ d(\gamma,\gamma')\leq \delta}} (X_{\gamma}-X_{\gamma'}) + \max_{i \in \{1, \dots, N\}} \lvert X_{t_{i}}-X_{t_{1}} \rvert\\
    &\leq \sup_{\substack{\gamma,\gamma' \in T \\ d(\gamma,\gamma')\leq \delta}} (X_{\gamma}-X_{\gamma'}) + \max_{t_{i}, t_{j} \in U} \lvert X_{t_{i}}-X_{t_{j}}\rvert.
\end{align*}
The same bound holds given any other $\tilde{t} \in T$. Adding together yields
\[
    \sup_{t, \tilde{t} \in T }(X_{t}-X_{\tilde{t}}) \leq 2 \sup_{\substack{\gamma,\gamma' \in T \\ d(\gamma,\gamma')\leq \delta}} (X_{\gamma}-X_{\gamma'}) + 2 \max_{t_{i}, t_{j} \in U} \lvert X_{t_{i}}-X_{t_{j}}\rvert.
\]
We can now take the expected value and plug in \eqref{eq:dudley_bound_on_maxima_U}. This concludes the proof.
\end{proof}

\begin{remark}
    The standard version of Dudley's inequality is stated in terms of the magnitute \( \E\left[\sup_{t \in T} X_{t}\right] \) instead of increments.
    It can be recovered from our version, noting that because of the mean zero assumption we can choose an arbitrary \( t_{0} \in T \) and write
    \[
        \E\left[\sup_{t \in T} X_{t}\right] = \E\left[ \sup_{t \in T}(X_{t}-X_{t_{0}})\right] \leq \E\left[\sup_{s,t \in T} (X_{t} - X_{s})\right] 
    \]
    Then we take the limit \( \delta \to 0 \) and get
    \[
        \E\left[\sup_{t \in T} X_{t}\right] \leq 32 \int_{0}^{\infty} \sqrt{\log \mathcal{N}(\varepsilon,T,d_{X})}\dx[\varepsilon].
    \] 
    The factor of 32 is not sharp and could be further improved by modifying the proof~\cite[p. 140]{wainwright2019high}.
    
\end{remark}








% As it turns out, Dudley's inequality is not sharp.
% Generic chaining can lead to a sharp inequality.

% \begin{theorem}[Generic chaining bound]\label{thm:generic_chaining_bound}
%     Theorem 8.5.3 in~\cite[p.221]{vershynin2020high}, extension of Theorem 8.1.4
%     Needs a definition of Talagrand's functional first \textcolor{red}{I think this is too much..}
% \end{theorem}
% \begin{proof}
%     This could be an exercise to understand how chaining works. \qedhere
% \end{proof}
% Named after Vapnik and Chervonenkis, VC classes allow \dots \textcolor{red}{can probably omit VC classes}
% \begin{definition}[VC Classes]
% \( \mathcal{C} \) is called a VC class of index \( v \) if it does not shatter any subset of \( \Omega \) of cardinality \( v + 1 \), but does shatter at least a subset of cardinality \( v \). \( \mathcal{C} \) shatters \( \{ x_{1}, \dots, x_{n} \} \) if given a subset $I$ of \( \{1, \dots, n \} \), we can find a \( C in \mathcal{C} \), such that \( x_{i} \in \mathcal{C} \) if and only if \( i \in I \).
% \end{definition}
The following is a lower bound counterpart to Dudley's inequality.
\begin{theorem}[Sudakov's minoration inequality]\index{chaining!Sudakov's minoration inequality}
    Let \((X_{t})_{t \in T}\) be a mean zero Gaussian process. Then for any \(\varepsilon \geq 0\), we have
    \[
        \E \sup_{t \in T} X_{t} \geq c \varepsilon \sqrt{\log \mathcal{N}( \varepsilon,T,d_{X})}
    \]
    where \(d_{X}\) is the canonical distance induced by the process and \(c\) is a constant.
\end{theorem}
The general idea of the proof is to compare the increments of the process \( \{ X_{t} \}_{t \in T} \) to the increments of a simpler Gaussian process \( \{ Y_{t} \}_{t \in T'} \)
defined by \( Y_{t} \coloneqq \frac{\varepsilon}{\sqrt{2}} g_{t} \), where $T'$ is a certain finite subset of $T$ and \( g_{t} \) are independent \( \mathcal{N}(0,1) \) random variables. And then apply the Sudakov-Fernique inequality.
For a proof of both Sudakov's minoration inequality and the Sudakov-Fernique inequality we refer the reader to~\cite{vershynin2020high}. 
\begin{theorem}[Sudakov-Fernique inequality]\index{Sudakov-Fernique inequality}
    Let \( (X_{t})_{t \in T} \) and \( (Y_{t})_{t \in T} \) be two mean zero Gaussian processes. Assume that for all \( t,s \in T \), we have
    \[
        \E\left[(X_{t}-X_{s})^2\right] \leq \E\left[(Y_{t}-Y_{s})^2\right].
    \]
    Then
    \[
        \E\left[\sup_{t \in T} X_{t}\right] \leq \E\left[\sup_{t \in T} Y_{t}\right].
    \]   
\end{theorem}
%
%
\begin{theorem}[Talagrand inequality]\index{chaining!Talagrand inequality}
    ~\label{thm:talagrand}
    \cite[Thm. 2.4]{talagrand1994sharper}
    Consider a Gaussian process \( \{ X_{t} \}_{t \in T} \). Let \( \sigma^2 = \sup_{t \in T} \E[X_{t}^2] \).
    Consider the canonical distance on $T$ given by \( d_{X}(s,t)^2 = \E\left[(X_{s}-X_{t})^2\right]\).
    Assume that for some constant \( A > \sigma \), some \( v > 0 \) and some \( 0 \leq \varepsilon_{0} \leq \sigma \) we have 
    \[
        \mathcal{N}(T,d,\varepsilon) \leq (A/\varepsilon)^{v}
    \]
    whenever \( \varepsilon < \varepsilon_{0} \).
    Then for \( u \geq \sigma^2[(1+\sqrt{v})/\varepsilon_{0}] \) we have
    \[
        \Prob \left( \sup_{t \in T} X_{t} \geq u \right) \leq \left( \frac{K A u}{\sqrt{v} \sigma^2} \right)^{v} \Phi(\frac{u}{\sigma})
        \leq  \left(\frac{K A u}{\sqrt{v} \sigma^2} \right)^{v} e^{\frac{-u^2}{2\sigma^2}},
    \]
    % \textcolor{red}{Factor \( \frac{\sigma}{u} \) missing from last inequality ?
    % We have \( \Phi(t) \leq \frac{1}{\sqrt{2\pi}}\frac{1}{t} e^{-t^2/2} \)}
    where $\Phi$ denotes the \textsc{cdf} of the standard normal distribution. If \( \varepsilon_{0} = \sigma \), the condition on $g$ is \( g \geq \sigma[1+\sqrt{v}] \).
     
\end{theorem}